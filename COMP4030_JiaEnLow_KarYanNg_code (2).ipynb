{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BRIEF OVERVIEW \n",
    "\n",
    "there are two pipelines : \n",
    "1) Jia En Low :  ordinal encoder + label encoder -> MICE imputer -> standard scaler -> multitaskelasticnet feature selection -> GBT Model / Logistic Model \n",
    "\n",
    "2) Kar Yan Ng :   label encoder -> simple imputer(mean) -> standard scaler -> PLS dimensionality reduction -> GBT Model / Logistic Model \n",
    "\n",
    "Analysis has been carried out by both of us at the end of the code \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install fancyimpute==0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install scikit.learn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install -c conda-forge sklearn.metrics==1.0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.impute import KNNImputer\n",
    "from fancyimpute import IterativeImputer\n",
    "from numpy import set_printoptions\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold, RepeatedStratifiedKFold\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from statistics import mean \n",
    "from sklearn.linear_model import MultiTaskElasticNet, MultiTaskElasticNetCV,  MultiTaskLassoCV\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.model_selection import cross_validate, KFold\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_predict, KFold\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('training_set_features.csv')\n",
    "labels = pd.read_csv('training_set_labels.csv')\n",
    "train_df_labels = pd.merge(train_df, labels, how= 'inner' ,on = 'respondent_id')\n",
    "test_df = pd.read_csv('test_set_features.csv')\n",
    "frames = [train_df, test_df]\n",
    "df_merged = pd.concat(frames)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPLORING DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_labels.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missingdata = train_df_labels.iloc[:, 1:39].notnull()\n",
    "for column in missingdata.columns.values.tolist():\n",
    "    print(column)\n",
    "    print (missingdata[column].value_counts())\n",
    "    print(\"\") "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PREPROCESSING "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "drop missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_labels.dropna(thresh=16, inplace = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "combination of label and ordinal encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ORDINAL ENCODING \n",
    "\n",
    "def ordinal_encoder(data,feature,feature_rank):\n",
    "    \n",
    "    ordinal_dict = {}\n",
    "    \n",
    "    for i, feature_value in enumerate(feature_rank):\n",
    "        ordinal_dict[feature_value]=i+1\n",
    "    \n",
    "    data[feature] = data[feature].map(lambda x: ordinal_dict[x])\n",
    "    \n",
    "    return data\n",
    "\n",
    "# replace with mode for income_poverty column\n",
    "from collections import Counter\n",
    "Counter(train_df_labels[\"income_poverty\"])\n",
    "train_df_labels['income_poverty'].fillna('<= $75,000, Above Poverty', inplace=True)\n",
    "\n",
    "# then ordinal encode ( since OE cannot take NA values)\n",
    "ordinal_encoder(train_df_labels, 'age_group', ['18 - 34 Years', '35 - 44 Years', '45 - 54 Years', '55 - 64 Years', '65+ Years'])\n",
    "ordinal_encoder(train_df_labels, 'income_poverty', ['Below Poverty', '<= $75,000, Above Poverty', '> $75,000'])\n",
    "\n",
    "\n",
    "# LABEL ENCODING  \n",
    "le = LabelEncoder()\n",
    "cols_to_encode = ['employment_industry', 'employment_occupation', 'education', 'health_insurance', 'doctor_recc_h1n1', 'doctor_recc_seasonal']\n",
    "\n",
    "# apply label encoding to selected columns\n",
    "for col in cols_to_encode:\n",
    "    train_df_labels[col] = le.fit_transform(train_df_labels[col])\n",
    "\n",
    "\n",
    "train_df_labels_withNA = train_df_labels.apply(lambda series: pd.Series(\n",
    "    le.fit_transform(series[series.notnull()]),\n",
    "    index=series[series.notnull()].index\n",
    "))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dealing with missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_labels_withNA = train_df_labels_withNA.astype(pd.Int64Dtype() )\n",
    "\n",
    "# calling the  MICE class\n",
    "mice_imputer = IterativeImputer()\n",
    "# imputing the missing value with mice imputer\n",
    "mice_imputed_df = mice_imputer.fit_transform(train_df_labels_withNA)\n",
    "\n",
    "mice_imputed_df = mice_imputed_df.round(0)\n",
    "\n",
    "mice_imputed_df = pd.DataFrame(mice_imputed_df, columns=train_df_labels_withNA.columns)\n",
    "mice_imputed_df = mice_imputed_df.astype(pd.Int64Dtype() )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "corr matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrMatt = mice_imputed_df.corr()\n",
    "#generate a mask for the upper triangle\n",
    "mask = np.zeros_like(corrMatt) # returns the matrix with each value as 0\n",
    "mask[np.triu_indices_from(mask)] = True # value 1 in upper triangle of the matrix \n",
    "\n",
    "#set up matplot fig \n",
    "fig, ax = plt.subplots(figsize = (20,12))\n",
    "plt.title('Flu dataset correlation')\n",
    "\n",
    "#generate a custom diverging colormap \n",
    "cmap= sns.diverging_palette(260,10,as_cmap = True) \n",
    "\n",
    "#Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corrMatt,vmax = 1.2, square = False, cmap = cmap , mask = mask, ax= ax, annot = True, fmt = '.2g', linewidths = 1 )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split dataset to features and outcome "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1n1 = mice_imputed_df.h1n1_vaccine.astype('int')\n",
    "seas = mice_imputed_df.seasonal_vaccine.astype('int')\n",
    "x = mice_imputed_df.drop(columns= ['h1n1_vaccine', 'seasonal_vaccine'], axis= 1)\n",
    "\n",
    "# target multilabel output \n",
    "y = pd.concat([seas, h1n1], axis =1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit_transform(x)\n",
    "scaled_x = pd.DataFrame(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PIPELINE BY JIA EN LOW\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOGISTIC REGRESSION + MULTITASKELASTICNET"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "before feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_predict, KFold\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf_lr_bfs = MultiOutputClassifier(LogisticRegression())\n",
    "clf_lr_bfs.fit(scaled_x, y)\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Use cross_val_predict to obtain probability predictions\n",
    "y_pred_proba = cross_val_predict(clf_lr_bfs, scaled_x, y, cv=cv, method='predict_proba')\n",
    "\n",
    "# Separate the probabilities for each target variable\n",
    "y_pred_proba_target1 = np.array([prob[1] for prob in y_pred_proba[0]])\n",
    "y_pred_proba_target2 = np.array([prob[1] for prob in y_pred_proba[1]])\n",
    "\n",
    "# # Calculate the ROC AUC scores for each target variable\n",
    "roc_auc_target1 = roc_auc_score(y.iloc[:, 0], y_pred_proba_target1)\n",
    "roc_auc_target2 = roc_auc_score(y.iloc[:, 1], y_pred_proba_target2)\n",
    "\n",
    "# # Print the ROC AUC scores\n",
    "print(\"ROC AUC score for Seasonal Flu vaccine:\", roc_auc_target1)\n",
    "print(\"ROC AUC score for H1N1 Vaccine:\", roc_auc_target2)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "after feature selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nested K-fold \n",
    "from sklearn.model_selection import KFold, GridSearchCV, cross_val_predict\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Define the pipeline with the model and feature selection\n",
    "pipeline = Pipeline([ \n",
    "    ('fs', SelectFromModel(MultiTaskElasticNet())), \n",
    "    ('clf',  MultiOutputClassifier(LogisticRegression(), n_jobs = -1))\n",
    "])\n",
    "\n",
    "# Define the parameter grid for hyperparameter tuning\n",
    "grid_params = {\n",
    "    'fs__estimator__alpha': [0.01, 0.1, 1.0, 10],\n",
    "    'fs__estimator__l1_ratio': [0.1, 0.3, 0.5, 1.0]\n",
    "}\n",
    "\n",
    "# Define the outer cross-validation strategy\n",
    "outer_cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize variables to store the cross-validation results\n",
    "roc_auc_scores_target1 = []\n",
    "roc_auc_scores_target2 = []\n",
    "\n",
    "# Outer loop for nested cross-validation\n",
    "for train_outer, test_outer in outer_cv.split(scaled_x, y):\n",
    "    # Split the data into training and test sets for the outer fold\n",
    "    x_train_outer, x_test_outer = scaled_x.loc[train_outer,:], scaled_x.loc[test_outer,:]\n",
    "    \n",
    "    y_train_outer, y_test_outer = y.iloc[train_outer], y.iloc[test_outer]\n",
    "    \n",
    "    # Define the inner cross-validation strategy\n",
    "    inner_cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Perform grid search with cross-validation on the training set of the outer fold\n",
    "    clf = GridSearchCV(pipeline, grid_params, cv=inner_cv, scoring='roc_auc', return_train_score=True)\n",
    "    clf.fit(x_train_outer, y_train_outer)\n",
    "    logistic_best = clf.best_estimator_\n",
    "    \n",
    "    # Use cross_val_predict to obtain probability predictions on the test set of the outer fold\n",
    "    y_pred_proba = cross_val_predict(logistic_best, x_test_outer, y_test_outer, cv=inner_cv, method='predict_proba')\n",
    "    \n",
    "    # Separate the probabilities for each target variable\n",
    "    y_pred_proba_target1 = np.array([prob[1] for prob in y_pred_proba[0]])\n",
    "    y_pred_proba_target2 = np.array([prob[1] for prob in y_pred_proba[1]])\n",
    "    \n",
    "    # Calculate the ROC AUC scores for each target variable and store them\n",
    "    roc_auc_scores_target1.append(roc_auc_score(y_test_outer.iloc[:, 0], y_pred_proba_target1))\n",
    "    roc_auc_scores_target2.append(roc_auc_score(y_test_outer.iloc[:, 1], y_pred_proba_target2))\n",
    "\n",
    "# Print the mean ROC AUC scores for each target variable across all outer folds\n",
    "print(\"Mean ROC AUC score for Seasonal Flu vaccine:\", np.mean(roc_auc_scores_target1))\n",
    "print(\"Mean ROC AUC score for H1N1 Vaccine:\", np.mean(roc_auc_scores_target2))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PIPELINE BY KAR YAN NG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, cross_val_predict\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.cross_decomposition import PLSRegression, CCA\n",
    "\n",
    "# Load data\n",
    "features_dataset = pd.read_csv('training_set_features.csv') \n",
    "target_dataset = pd.read_csv('training_set_labels.csv')  \n",
    "# Preprocess the features dataset\n",
    "\n",
    "categorical_columns = features_dataset.select_dtypes(include=['object']).columns\n",
    "numerical_columns = features_dataset.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Create preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', SimpleImputer(strategy='mean'), numerical_columns),\n",
    "        ('cat', OneHotEncoder(), categorical_columns)\n",
    "    ])\n",
    "\n",
    "# Apply preprocessing\n",
    "features_dataset = preprocessor.fit_transform(features_dataset)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "scaled_x = scaler.fit_transform(features_dataset)\n",
    "\n",
    "# Create the target variable dataset\n",
    "y = target_dataset[['h1n1_vaccine', 'seasonal_vaccine']] \n",
    "\n",
    "# Define the pipelines with the models, one for PLS and another for CCA, now with Logistic Regression\n",
    "pls_pipeline = Pipeline([\n",
    "    ('fs', SelectFromModel(PLSRegression(n_components=2))),\n",
    "    ('clf', MultiOutputClassifier(LogisticRegression(), n_jobs=-1))\n",
    "])\n",
    "\n",
    "#cca_pipeline = Pipeline([\n",
    "#    ('fs', SelectFromModel(CCA(n_components=2))),\n",
    "#    ('clf', MultiOutputClassifier(LogisticRegression(), n_jobs=-1))\n",
    "#])\n",
    "\n",
    "# Function to perform nested cross-validation and return mean ROC AUC scores\n",
    "def nested_cv(pipeline):\n",
    "    outer_cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    roc_auc_scores_target1 = []\n",
    "    roc_auc_scores_target2 = []\n",
    "    for train_outer, test_outer in outer_cv.split(scaled_x, y):\n",
    "        x_train_outer, x_test_outer = scaled_x[train_outer], scaled_x[test_outer]\n",
    "        y_train_outer, y_test_outer = y.iloc[train_outer], y.iloc[test_outer]\n",
    "        inner_cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        pipeline.fit(x_train_outer, y_train_outer)\n",
    "        y_pred_proba = cross_val_predict(pipeline, x_test_outer, y_test_outer, cv=inner_cv, method='predict_proba')\n",
    "        y_pred_proba_target1 = y_pred_proba[0][:, 1]\n",
    "        y_pred_proba_target2 = y_pred_proba[1][:, 1]\n",
    "        roc_auc_scores_target1.append(roc_auc_score(y_test_outer.iloc[:, 0], y_pred_proba_target1))\n",
    "        roc_auc_scores_target2.append(roc_auc_score(y_test_outer.iloc[:, 1], y_pred_proba_target2))\n",
    "    return np.mean(roc_auc_scores_target1), np.mean(roc_auc_scores_target2)\n",
    "\n",
    "# Perform nested cross-validation for the PLS pipeline\n",
    "pls_roc_auc_scores = nested_cv(pls_pipeline)\n",
    "\n",
    "# Perform nested cross-validation for the CCA pipeline\n",
    "#cca_roc_auc_scores = nested_cv(cca_pipeline)\n",
    "\n",
    "# Print the mean ROC AUC scores for each pipeline\n",
    "print(\"PLS Pipeline\")\n",
    "print(\"Mean ROC AUC score for H1N1 Vaccine:\", pls_roc_auc_scores[0])\n",
    "print(\"Mean ROC AUC score for Seasonal Flu Vaccine:\", pls_roc_auc_scores[1])\n",
    "#print(\"\\nCCA Pipeline\")\n",
    "#print(\"Mean ROC AUC score for H1N1 Vaccine:\", cca_roc_auc_scores[0])\n",
    "#print(\"Mean ROC AUC score for Seasonal Flu Vaccine:\", cca_roc_auc_scores[1])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CCA DIMENSIONALITY REDUCTION  + ONEHOTENCODER + LOGISTIC REGRESSION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold, GridSearchCV, cross_val_predict\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.cross_decomposition import PLSRegression, CCA\n",
    "\n",
    "# Load data\n",
    "features_dataset = pd.read_csv('training_set_features.csv')\n",
    "target_dataset = pd.read_csv('training_set_labels.csv')\n",
    "\n",
    "# Make copies of the original dataframes\n",
    "K_features_dataset = features_dataset.copy()\n",
    "K_target_dataset = target_dataset.copy()\n",
    "\n",
    "# Preprocess the features dataset\n",
    "categorical_columns = K_features_dataset.select_dtypes(include=['object']).columns\n",
    "numerical_columns = K_features_dataset.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# One-hot encoding for categorical features\n",
    "encoder = OneHotEncoder()\n",
    "encoded_categorical = encoder.fit_transform(K_features_dataset[categorical_columns]).toarray()\n",
    "\n",
    "# Impute missing values in numerical columns\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "K_features_dataset[numerical_columns] = imputer.fit_transform(K_features_dataset[numerical_columns])\n",
    "\n",
    "# Concatenate the encoded categorical and numerical features\n",
    "scaled_x = np.concatenate([encoded_categorical, K_features_dataset[numerical_columns]], axis=1)\n",
    "\n",
    "# Create the target variable dataset\n",
    "y = K_target_dataset[['h1n1_vaccine', 'seasonal_vaccine']]\n",
    "\n",
    "# Components to iterate over\n",
    "components = [2]\n",
    "\n",
    "for comp in components:\n",
    "    pls_pipeline = Pipeline([\n",
    "        ('fs', SelectFromModel(PLSRegression(n_components=comp))),\n",
    "        ('clf', MultiOutputClassifier(LogisticRegression(), n_jobs=-1))\n",
    "    ])\n",
    "\n",
    "#    cca_pipeline = Pipeline([\n",
    "#       ('fs', SelectFromModel(CCA(n_components=comp))),\n",
    "#       ('clf', MultiOutputClassifier(LogisticRegression(), n_jobs=-1))\n",
    "#    ])\n",
    "\n",
    "    outer_cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    def nested_cv(pipeline):\n",
    "        roc_auc_scores_target1 = []\n",
    "        roc_auc_scores_target2 = []\n",
    "        for train_outer, test_outer in outer_cv.split(scaled_x, y):\n",
    "            x_train_outer, x_test_outer = scaled_x[train_outer], scaled_x[test_outer]\n",
    "            y_train_outer, y_test_outer = y.iloc[train_outer], y.iloc[test_outer]\n",
    "            inner_cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "            pipeline.fit(x_train_outer, y_train_outer)\n",
    "            y_pred_proba = cross_val_predict(pipeline, x_test_outer, y_test_outer, cv=inner_cv, method='predict_proba')\n",
    "            y_pred_proba_target1 = y_pred_proba[0][:, 1]\n",
    "            y_pred_proba_target2 = y_pred_proba[1][:, 1]\n",
    "            roc_auc_scores_target1.append(roc_auc_score(y_test_outer.iloc[:, 0], y_pred_proba_target1))\n",
    "            roc_auc_scores_target2.append(roc_auc_score(y_test_outer.iloc[:, 1], y_pred_proba_target2))\n",
    "        return np.mean(roc_auc_scores_target1), np.mean(roc_auc_scores_target2)\n",
    "\n",
    "    pls_roc_auc_scores = nested_cv(pls_pipeline)\n",
    "    cca_roc_auc_scores = nested_cv(cca_pipeline)\n",
    "\n",
    "    print(f\"PLS Pipeline with {comp} components\")\n",
    "    print(\"Mean ROC AUC score for H1N1 Vaccine:\", pls_roc_auc_scores[0])\n",
    "    print(\"Mean ROC AUC score for Seasonal Flu Vaccine:\", pls_roc_auc_scores[1])\n",
    "\n",
    "#     print(f\"\\nCCA Pipeline with {comp} components\")\n",
    "#     print(\"Mean ROC AUC score for H1N1 Vaccine:\", cca_roc_auc_scores[0])\n",
    "#     print(\"Mean ROC AUC score for Seasonal Flu Vaccine:\", cca_roc_auc_scores[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLSRegression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "before feature selection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PIPELINE BY JIA EN LOW "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRADIENT BOOSTING CLASSIFIER "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_x = pd.DataFrame(scaled_x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "before feature selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf_beforefs =  MultiOutputClassifier(GradientBoostingClassifier())\n",
    "clf_beforefs.fit(scaled_x, y)\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Use cross_val_predict to obtain probability predictions\n",
    "y_pred_proba = cross_val_predict(clf_beforefs, scaled_x, y, cv=cv, method='predict_proba')\n",
    "\n",
    "# Separate the probabilities for each target variable\n",
    "y_pred_proba_target1 = np.array([prob[1] for prob in y_pred_proba[0]])\n",
    "y_pred_proba_target2 = np.array([prob[1] for prob in y_pred_proba[1]])\n",
    "\n",
    "# # Calculate the ROC AUC scores for each target variable\n",
    "roc_auc_target1 = roc_auc_score(y.iloc[:, 0], y_pred_proba_target1)\n",
    "roc_auc_target2 = roc_auc_score(y.iloc[:, 1], y_pred_proba_target2)\n",
    "\n",
    "# # Print the ROC AUC scores\n",
    "print(\"ROC AUC score for Seasonal Flu vaccine:\", roc_auc_target1)\n",
    "print(\"ROC AUC score for H1N1 Vaccine:\", roc_auc_target2)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "after feature selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(scaled_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.feat/ure_selection import SelectFromModel\n",
    "from sklearn.linear_model import MultiTaskElasticNet\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('fs', SelectFromModel(MultiTaskElasticNet())),\n",
    "    ('clf', MultiOutputClassifier(GradientBoostingClassifier(), n_jobs=-1))\n",
    "])\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "grid_params = {\n",
    "    'fs__estimator__alpha': [0.01, 0.1, 1.0, 10],\n",
    "    'fs__estimator__l1_ratio': [0.1, 0.3, 0.5, 1.0],\n",
    "    'clf__estimator__learning_rate': [0.01, 0.05, 0.1],\n",
    "    'clf__estimator__max_depth': [5, 8, 12],\n",
    "    'clf__estimator__criterion': ['friedman_mse', 'squared_error']\n",
    "}\n",
    "\n",
    "# Define the nested k-fold cross-validation\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define the GridSearchCV object with nested k-fold cross-validation\n",
    "clf = GridSearchCV(\n",
    "    pipeline,\n",
    "    grid_params,\n",
    "    cv=cv,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Perform the nested k-fold cross-validation\n",
    "roc_auc_scores_target1 = []\n",
    "roc_auc_scores_target2 = []\n",
    "for train_outer_idx, test_outer_idx in cv.split(scaled_x, y):\n",
    "    X_train_outer, X_test_outer = scaled_x.iloc[train_outer_idx], scaled_x.iloc[test_outer_idx]\n",
    "    y_train_outer, y_test_outer = y.iloc[train_outer_idx], y.iloc[test_outer_idx]\n",
    "    \n",
    "    \n",
    "    clf.fit(X_train_outer, y_train_outer)\n",
    "    rf_best = clf.best_estimator_\n",
    "\n",
    "        # Use cross_val_predict to obtain probability predictions on the test set of the outer fold\n",
    "    y_pred_proba = cross_val_predict(rf_best, X_test_outer, y_test_outer, cv=cv, method='predict_proba')\n",
    "    \n",
    "    # Separate the probabilities for each target variable\n",
    "    y_pred_proba_target1 = np.array([prob[1] for prob in y_pred_proba[0]])\n",
    "    y_pred_proba_target2 = np.array([prob[1] for prob in y_pred_proba[1]])\n",
    "    \n",
    "    # Calculate the ROC AUC scores for each target variable and store them\n",
    "    roc_auc_scores_target1.append(roc_auc_score(y_test_outer.iloc[:, 0], y_pred_proba_target1))\n",
    "    roc_auc_scores_target2.append(roc_auc_score(y_test_outer.iloc[:, 1], y_pred_proba_target2))\n",
    "\n",
    "# Print the mean ROC AUC scores for each target variable across all outer folds\n",
    "print(\"Mean ROC AUC score for Seasonal Flu vaccine:\", np.mean(roc_auc_scores_target1))\n",
    "print(\"Mean ROC AUC score for H1N1 Vaccine:\", np.mean(roc_auc_scores_target2))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PIPELINE BY KAR YAN NG"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CCA DIMENSIONALITY REDUCTION  + ONEHOTENCODER + LOGISTIC REGRESSION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, cross_val_predict, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.cross_decomposition import PLSRegression, CCA\n",
    "\n",
    "# Load data\n",
    "features_dataset = pd.read_csv('training_set_features.csv')  # replace with your actual file\n",
    "target_dataset = pd.read_csv('training_set_labels.csv')  # replace with your actual file\n",
    "\n",
    "# Preprocess the features dataset\n",
    "categorical_columns = features_dataset.select_dtypes(include=['object']).columns\n",
    "numerical_columns = features_dataset.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Create preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "     transformers=[\n",
    "        ('num', SimpleImputer(strategy='mean'), numerical_columns),\n",
    "        ('cat', OneHotEncoder(), categorical_columns)\n",
    " ])\n",
    "\n",
    "# Apply preprocessing\n",
    "features_dataset = preprocessor.fit_transform(features_dataset)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "scaled_x = scaler.fit_transform(features_dataset)\n",
    "\n",
    "# Create the target variable dataset\n",
    "y = target_dataset[['h1n1_vaccine', 'seasonal_vaccine']]  \n",
    "\n",
    "# Define the pipelines with the models, one for PLS and another for CCA, now with Gradient Boosting\n",
    "pls_pipeline = Pipeline([\n",
    "    ('fs', SelectFromModel(PLSRegression(n_components=2))),\n",
    "    ('clf', MultiOutputClassifier(GradientBoostingClassifier(), n_jobs=-1))\n",
    "])\n",
    "\n",
    "# cca_pipeline = Pipeline([\n",
    "#     ('fs', SelectFromModel(CCA(n_components=2))),\n",
    "#     ('clf', MultiOutputClassifier(GradientBoostingClassifier(), n_jobs=-1))\n",
    "# ])\n",
    "\n",
    "# Define the parameter grids for GridSearchCV\n",
    "pls_param_grid = {\n",
    "    'fs__estimator__n_components': [1, 2, 3],\n",
    "    'clf__estimator__n_estimators': [50, 100, 200],\n",
    "    'clf__estimator__learning_rate': [0.1, 0.05, 0.01]\n",
    "}\n",
    "\n",
    "# cca_param_grid = {\n",
    "#    'fs__estimator__n_components': [1, 2, 3],\n",
    "#    'clf__estimator__n_estimators': [50, 100, 200],\n",
    "#    'clf__estimator__learning_rate': [0.1, 0.05, 0.01]\n",
    "#}\n",
    "\n",
    "# Perform nested cross-validation with GridSearchCV for the PLS pipeline\n",
    "pls_grid_search = GridSearchCV(pls_pipeline, param_grid=pls_param_grid, cv=5, scoring='roc_auc')\n",
    "pls_grid_search.fit(scaled_x, y)\n",
    "best_pls_params = pls_grid_search.best_params_\n",
    "best_pls_roc_auc_scores = nested_cv(pls_grid_search.best_estimator_)\n",
    "\n",
    "# Perform nested cross-validation with GridSearchCV for the CCA pipeline\n",
    "# cca_grid_search = GridSearchCV(cca_pipeline, param_grid=cca_param_grid, cv=5, scoring='roc_auc')\n",
    "# cca_grid_search.fit(scaled_x, y)\n",
    "# best_cca_params = cca_grid_search.best_params_\n",
    "# best_cca_roc_auc_scores = nested_cv(cca_grid_search.best_estimator_)\n",
    "\n",
    "# Print the best parameters and mean ROC AUC scores for each pipeline\n",
    "print(\"Best parameters for PLS pipeline:\", best_pls_params)\n",
    "print(\"Mean ROC AUC score for H1N1 Vaccine (PLS):\", best_pls_roc_auc_scores[0])\n",
    "print(\"Mean ROC AUC score for Seasonal Flu Vaccine (PLS):\", best_pls_roc_auc_scores[1])\n",
    "\n",
    "# print(\"\\nBest parameters for CCA pipeline:\", best_cca_params)\n",
    "# print(\"Mean ROC AUC score for H1N1 Vaccine (CCA):\", best_cca_roc_auc_scores[0])\n",
    "# print(\"Mean ROC AUC score for Seasonal Flu Vaccine (CCA):\", best_cca_roc_auc_scores[1])\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANALYSIS - BY JIA EN LOW "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "number of features with corresponding roc auc score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the performance \n",
    "from sklearn.linear_model import MultiTaskElasticNetCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define a range of alpha values to use for regularization\n",
    "# alphas = [0.001, 0.01, 0.1, 1, 10]\n",
    "\n",
    "# Define a range of numbers of features to select\n",
    "num_features = range(8,36,2)\n",
    "\n",
    "# Initialize an empty list to store ROC AUC scores\n",
    "roc_means = []\n",
    "\n",
    "# Train a MultitaskElasticNet model for each number of features\n",
    "for n in num_features:\n",
    "    # Fit the model with L1 and L2 regularization using cross-validation\n",
    "    selector = SelectFromModel(max_features=n , estimator = MultiTaskElasticNet(alpha=0.1, l1_ratio=0.1)).fit(scaled_x, y)\n",
    "    X_selected = selector.transform(scaled_x)\n",
    "    model = MultiOutputClassifier(LogisticRegression())\n",
    "    model.fit(X_selected, y)\n",
    "    # Compute the ROC AUC score using cross-validation\n",
    "    # Separate the probabilities for each target variable\n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    # Use cross_val_predict to obtain probability predictions\n",
    "    y_pred_proba = cross_val_predict(model, X_selected, y, cv=cv, method='predict_proba')\n",
    "    y_pred_proba_target1 = np.array([prob[1] for prob in y_pred_proba[0]])\n",
    "    y_pred_proba_target2 = np.array([prob[1] for prob in y_pred_proba[1]])\n",
    "\n",
    "    # # Calculate the ROC AUC scores for each target variable\n",
    "    roc_auc_target1 = roc_auc_score(y.iloc[:, 0], y_pred_proba_target1)\n",
    "    roc_auc_target2 = roc_auc_score(y.iloc[:, 1], y_pred_proba_target2)\n",
    "    # # Print the ROC AUC scores\n",
    "    print(\"ROC AUC score for Seasonal Flu vaccine:\", roc_auc_target1)\n",
    "    print(\"ROC AUC score for H1N1 Vaccine:\", roc_auc_target2)\n",
    "    roc_mean = (roc_auc_target1+roc_auc_target2)/2\n",
    "    roc_means.append(roc_mean)\n",
    "    \n",
    "# Plot the ROC AUC scores vs the number of features selected\n",
    "plt.plot(num_features, roc_means)\n",
    "plt.xlabel('Number of features selected')\n",
    "plt.ylabel('ROC AUC score')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SHAP values before feature selection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.LinearExplainer(clf_lr_bfs.estimators_[1], scaled_x)\n",
    "shap_values = explainer.shap_values(scaled_x)\n",
    "shap.summary_plot(shap_values, features= scaled_x.columns, plot_type='bar')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GBT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## interpretable Using SHAP \n",
    "explainer = shap.Explainer(clf_beforefs.estimators_[1])\n",
    "shap_values = explainer(scaled_x)\n",
    "shap.summary_plot(shap_values, scaled_x, plot_type='bar')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importance graph"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fit on multittaskelasticnet to get feature importance\n",
    "estimator = MultiTaskElasticNet(alpha=0.1, l1_ratio=0.1)\n",
    "selector = SelectFromModel(estimator)\n",
    "selector.fit(scaled_x, y)\n",
    "\n",
    "# # Transform the data using the feature selector\n",
    "X_selected = selector.transform(scaled_x)\n",
    "\n",
    "# # Print the selected features\n",
    "print(\"Selected features: \", selector.get_feature_names_out())\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get feature importance\n",
    "feature_importance = selector.estimator_.coef_\n",
    "\n",
    "# Compute absolute feature importance\n",
    "abs_feature_importance = abs(feature_importance)\n",
    "\n",
    "# Compute mean feature importance across tasks\n",
    "mean_feature_importance = abs_feature_importance.mean(axis=0)\n",
    "\n",
    "# Sort features by mean importance\n",
    "sorted_indices = mean_feature_importance.argsort()\n",
    "\n",
    "feature_names = selector.feature_names_in_\n",
    "# Get the feature names\n",
    "selected_features= selector.get_feature_names_out()\n",
    "\n",
    "# Reverse the order of feature names to match the descending order of importance\n",
    "feature_selected =  [feature_names[i] for i in sorted_indices]\n",
    "\n",
    "# Plot feature importances horizontally\n",
    "fig, ax = plt.subplots(figsize = (10,10))\n",
    "\n",
    "plt.barh(feature_selected, mean_feature_importance[sorted_indices])\n",
    "# plt.yticks(range(scaled_x.shape[1]), sorted_indices)\n",
    "plt.xlabel('Feature importance')\n",
    "plt.ylabel('Feature index')\n",
    "plt.title('Feature importances')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GBT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting performance of different number of features selected\n",
    "# getting the performance \n",
    "from sklearn.linear_model import MultiTaskElasticNetCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Define a range of numbers of features to select\n",
    "num_features = range(8,36,2)\n",
    "\n",
    "# Initialize an empty list to store ROC AUC scores\n",
    "roc_means = []\n",
    "\n",
    "# Train a MultitaskElasticNet model for each number of features\n",
    "for n in num_features:\n",
    "    # Fit the model with L1 and L2 regularization using cross-validation\n",
    "    selector = SelectFromModel(max_features=n , estimator = MultiTaskElasticNet(alpha=0.1, l1_ratio=0.1)).fit(scaled_x, y)\n",
    "    X_selected = selector.transform(scaled_x)\n",
    "    model = MultiOutputClassifier(GradientBoostingClassifier())\n",
    "    model.fit(X_selected, y)\n",
    "    # Compute the ROC AUC score using cross-validation\n",
    "    # Separate the probabilities for each target variable\n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    # Use cross_val_predict to obtain probability predictions\n",
    "    y_pred_proba = cross_val_predict(model, X_selected, y, cv=cv, method='predict_proba')\n",
    "    y_pred_proba_target1 = np.array([prob[1] for prob in y_pred_proba[0]])\n",
    "    y_pred_proba_target2 = np.array([prob[1] for prob in y_pred_proba[1]])\n",
    "\n",
    "    # # Calculate the ROC AUC scores for each target variable\n",
    "    roc_auc_target1 = roc_auc_score(y.iloc[:, 0], y_pred_proba_target1)\n",
    "    roc_auc_target2 = roc_auc_score(y.iloc[:, 1], y_pred_proba_target2)\n",
    "    # # Print the ROC AUC scores\n",
    "    print(\"ROC AUC score for Seasonal Flu vaccine:\", roc_auc_target1)\n",
    "    print(\"ROC AUC score for H1N1 Vaccine:\", roc_auc_target2)\n",
    "    roc_mean = (roc_auc_target1+roc_auc_target2)/2\n",
    "    roc_means.append(roc_mean)\n",
    "    \n",
    "# Plot the ROC AUC scores vs the number of features selected\n",
    "plt.plot(num_features, roc_means)\n",
    "plt.xlabel('Number of features selected')\n",
    "plt.ylabel('ROC AUC score')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANALYSIS - BY KAR YAN NG "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import cross_val_predict, KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "\n",
    "# Load data\n",
    "features_dataset = pd.read_csv('training_set_features.csv')\n",
    "target_dataset = pd.read_csv('training_set_labels.csv')\n",
    "\n",
    "# Create the target variable dataset\n",
    "target_dataset = target_dataset[['h1n1_vaccine', 'seasonal_vaccine']]\n",
    "\n",
    "# Preprocess the features dataset\n",
    "categorical_columns = features_dataset.select_dtypes(include=['object']).columns\n",
    "numerical_columns = features_dataset.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "encoded_categorical = encoder.fit_transform(features_dataset[categorical_columns]).toarray()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_numerical = scaler.fit_transform(features_dataset[numerical_columns])\n",
    "\n",
    "# Impute missing values in numerical columns\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "features_dataset[numerical_columns] = imputer.fit_transform(features_dataset[numerical_columns])\n",
    "\n",
    "# Concatenate encoded categorical and scaled numerical features\n",
    "scaled_x = np.concatenate((encoded_categorical, scaled_numerical), axis=1)\n",
    "\n",
    "# Create PLS object\n",
    "pls = PLSRegression(n_components=2)\n",
    "\n",
    "# Fit\n",
    "pls.fit(scaled_x, target_dataset)\n",
    "\n",
    "# Cross-validation\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "# Get predicted probabilities via cross-validation\n",
    "y_pred = cross_val_predict(pls, scaled_x, target_dataset, cv=kf, method='predict')\n",
    "\n",
    "# Compute ROC AUC scores for each target\n",
    "roc_auc_scores = []\n",
    "for i in range(target_dataset.shape[1]):\n",
    "    roc_auc_scores.append(roc_auc_score(target_dataset.iloc[:, i], y_pred[:, i]))\n",
    "\n",
    "print(\"ROC AUC scores:\", roc_auc_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_predict, KFold\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Load the dataset containing the target variables\n",
    "dfl = pd.read_csv('training_set_labels.csv')\n",
    "df = pd.read_csv('training_set_features.csv')\n",
    "\n",
    "# Preprocess the features dataset\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "numerical_columns = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "encoded_categorical = encoder.fit_transform(features_dataset[categorical_columns]).toarray()\n",
    "\n",
    "scaled_x = encoded_categorical\n",
    "\n",
    "# Make copies of the original dataframes\n",
    "features_dataset = df\n",
    "target_dataset = dfl[['h1n1_vaccine', 'seasonal_vaccine']]\n",
    "target_dataset = target_dataset.astype(int)\n",
    "\n",
    "# Compute ROC curves for each target\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "target_labels = ['h1n1_vaccine', 'seasonal_vaccine']  # Adjust this to your column names\n",
    "\n",
    "# Cross-validation\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "# Create PLS object\n",
    "pls = PLSRegression(n_components=2)\n",
    "y_pred_proba = cross_val_predict(pls, scaled_x, target_dataset, cv=kf, method='predict')\n",
    "\n",
    "for i in range(target_dataset.shape[1]):\n",
    "    fpr, tpr, _ = roc_curve(target_dataset.iloc[:, i], y_pred_proba[:, i])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.plot(fpr, tpr, label=f'ROC curve of class {i} (area = {roc_auc:.2f})')\n",
    "    \n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
